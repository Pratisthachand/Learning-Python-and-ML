{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-v2BWFnIKLg"
      },
      "outputs": [],
      "source": [
        "#Importing required packages.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns #lines 2 and 3 are for graphing #Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
        "import matplotlib.pyplot as plt #Matplotlib is a plotting library for creating static, animated, and interactive visualizations in Python. \n",
        "from sklearn.ensemble import RandomForestClassifier #Ensemble method creates multiple models and combines them to solve it.\n",
        "from sklearn.svm import SVC #Support Vector Classifier, is a supervised machine learning algorithm typically used for classification tasks.\n",
        "from sklearn import svm #Support vector machines (SVMs) are a particularly powerful and flexible class of supervised algorithms for both classification and regression and outlier detection.\n",
        "from sklearn.neural_network import MLPClassifier #MLPClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. \n",
        "\n",
        "#from sklearn.linear_model import SGDClassifier (Stochastic gradient descent is an optimization algorithm often used in machine learning applications to find the model parameters that correspond to the best fit between predicted and actual outputs.)\n",
        "from sklearn.metrics import confusion_matrix, classification_report #to evaluate the performance of a classifier \n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #standardscaler is for standardization #labelencoder- replace the categorical value with a numeric value between 0 and the number of classes minus 1 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Importing required packages.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "#Loading dataset\n",
        "wine = pd.read_csv('/content/winequality-red.csv',sep=';') #uploads the dataset to files section and then clicked to find the file path and pasted it here.\n",
        "\n",
        "print (wine.head()) #shows first five lines present in datasheet as default. for more values, put a number inside the brackets\n",
        "\n",
        "print (' ') #added this to seperate each section\n",
        "\n",
        "print(wine.info()) #non-null = no nun values here\n",
        " \n",
        "print (' ')\n",
        "\n",
        "print (wine.isnull().sum()) #shows how many null values are in each section\n",
        "\n"
      ],
      "metadata": {
        "id": "A6efE0cVJ121",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefd0922-41a3-4bed-bad7-d963b5a54c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality\n",
            "0   7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5                                                                                               \n",
            "1   7.8,0.88,0,2.6,0.098,25,67,0.9968,3.2,0.68,9.8,5                                                                                               \n",
            "2  7.8,0.76,0.04,2.3,0.092,15,54,0.997,3.26,0.65,...                                                                                               \n",
            "3  11.2,0.28,0.56,1.9,0.075,17,60,0.998,3.16,0.58...                                                                                               \n",
            "4   7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5                                                                                               \n",
            " \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                                                                                                                             Non-Null Count  Dtype \n",
            "---  ------                                                                                                                                             --------------  ----- \n",
            " 0   fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality  1599 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 12.6+ KB\n",
            "None\n",
            " \n",
            "fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Importing required packages.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns #lines 2 and 3 are for graphing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "#Loading dataset\n",
        "wine = pd.read_csv('/content/winequality-red.csv') #if i write sep=\";\" here after ....csv', the program doesn't work for some reason\n",
        "\n",
        "#Preprocessing data:\n",
        "\n",
        "bins = (2, 6.5, 8) # in wine.head part, you can see many different values in the quality column (ex: 5,6,7). now we are seperating that into just 2 bins of quality: good and bad. if 2<x<6.5= bad, 6.5<x<8 = good\n",
        "group_names = ['bad', 'good']\n",
        "wine['quality']= pd.cut(wine['quality'], bins= bins, labels = group_names)\n",
        "wine['quality'].unique()\n",
        "\n",
        "label_quality= LabelEncoder() #this replaces categorical value with a numeric value between 0 and the number of classes minus 1. here, as the number of classes is 2 (good and bad), the label encoder changes the values into 0 or 1 (2-1=1).\n",
        "\n",
        "wine['quality']= label_quality.fit_transform(wine['quality']) \n",
        "\n",
        "wine.head() #now we can see that in quality column, theres only 0 and 1 value. 0 =bad, 1 = good.\n",
        "\n",
        "wine['quality'].value_counts() #shows how many wines are good (1) and bad(0)\n",
        "\n",
        "sns.countplot(wine['quality']) #graphical representation of good and bad quality wine\n",
        "\n",
        "#Now seperate the dataset as response variable and feature variable:\n",
        "#this is to seperate the features we need to predict the quality of the wine adn the quality itself. so on the basis on other features of the wine- ex: acidity, suger, we are coding to predict the quality of the wine\n",
        "\n",
        "X= wine.drop('quality', axis=1) #x = all features - quality\n",
        "y= wine['quality'] #y = quality only\n",
        "\n",
        "# Train and Test splitting of data:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X,y, test_size= 0.2, random_state =42) #test size = 0.2 means 20% default size would be 0.25. random state is not too imp, its just a random number.\n",
        "\n",
        "#Applying Standard Scaling to get optimized result:\n",
        "\n",
        "sc= StandardScaler() # total sulfur dioxide column has very large values ex: 34, 54, 102 while the chloride column has values like 0.076 so they have very little impact compared to sulfur values. so we need to standardize all values to level the playing field.\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform (X_test)\n",
        "\n",
        "X_train[:10] #now we can see that our values are much more uniform.\n",
        "\n",
        "#3 MOST COMMONLY USED CLASSIFIERS- RFC, SVM, NERUAL NETWORK- WE WILL EXPLORE:\n",
        "\n",
        "#Random Forest Classifier: (best used for medium sized dataset)\n",
        "\n",
        "rfc= RandomForestClassifier (n_estimators=200) #200 = number of trees in the forest aka number of models in here. usually start with a higher number, then lower it to see if it keeps the same value. smaller the number, better the fit.\n",
        "rfc.fit(X_train, y_train) #fitting our training data into it\n",
        "pred_rfc=rfc.predict(X_test) #predicting\n",
        "\n",
        "#Let's see how well our model performed\n",
        " \n",
        "print (classification_report(y_test,pred_rfc)) #report shows how good are our actual values against our predicted values.\n",
        "\n",
        "print (confusion_matrix(y_test, pred_rfc)) #shows that we had 264 correct and 9 wrong for bad wine and alot of mislables for good wine. shows that we are good are predicting bad wine but not so good at predicting the good wine.\n",
        "\n",
        "print ('----------------------------------------------------------------')\n",
        "\n",
        "#SVM CLASSIFIER: (works better on smaller numbers)\n",
        "clf=svm.SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "pred_clf= clf.predict (X_test)\n",
        "\n",
        "print (classification_report(y_test,pred_clf))\n",
        "print (confusion_matrix(y_test, pred_clf))\n",
        "\n",
        "#we can see precision of rfc is better than svm. \n",
        "\n",
        "print ('----------------------------------------------------------------')\n",
        "\n",
        "#NEURAL NETWORKS: (can work with large amounts of data, good with image processing)\n",
        "\n",
        "mlpc= MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=500) # 3 layers of 11 size each. default iteration= 200. 500 iteration means that it is goinf through the data 500 times to program those diff layers and carefully adjust them.\n",
        "mlpc.fit(X_train, y_train)\n",
        "pred_mlpc=mlpc.predict(X_test)\n",
        "\n",
        "print (classification_report(y_test,pred_mlpc))\n",
        "print (confusion_matrix(y_test, pred_mlpc))\n",
        "\n",
        "#didn't do as good with labeling the bad wines.\n",
        "\n",
        "print ('----------------------------------------------------------------')\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "cm= accuracy_score(y_test, pred_rfc)\n",
        "print (cm)\n",
        "\n",
        "print ('----------------------------------------------------------------')\n",
        "\n",
        "#testing if a new wine is of good or bad quality:\n",
        "\n",
        "Xnew= [[7.3,0.58,0.00,2.0,0.065,15.0,21.0,0.9946,3.36,0.47,10.0]]\n",
        "Xnew= sc.transform(Xnew)\n",
        "ynew= rfc.predict(Xnew) #asking to predict the quality\n",
        "ynew\n",
        "\n",
        "#output shows-- array[0] which tells us that the wine is bad.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LhB4uq31Sffj",
        "outputId": "006d9c04-5c3b-4e3d-c294-5341c187af54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       273\n",
            "           1       0.67      0.51      0.58        47\n",
            "\n",
            "    accuracy                           0.89       320\n",
            "   macro avg       0.79      0.73      0.76       320\n",
            "weighted avg       0.88      0.89      0.88       320\n",
            "\n",
            "[[261  12]\n",
            " [ 23  24]]\n",
            "----------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       273\n",
            "           1       0.71      0.26      0.37        47\n",
            "\n",
            "    accuracy                           0.88       320\n",
            "   macro avg       0.80      0.62      0.65       320\n",
            "weighted avg       0.86      0.88      0.85       320\n",
            "\n",
            "[[268   5]\n",
            " [ 35  12]]\n",
            "----------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       273\n",
            "           1       0.69      0.51      0.59        47\n",
            "\n",
            "    accuracy                           0.89       320\n",
            "   macro avg       0.80      0.74      0.76       320\n",
            "weighted avg       0.88      0.89      0.89       320\n",
            "\n",
            "[[262  11]\n",
            " [ 23  24]]\n",
            "----------------------------------------------------------------\n",
            "0.890625\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASAUlEQVR4nO3de7BdZ1nH8e+PhIIo0JYcKybREzWDU1EEzpSOjE6HKrRVSHWg045CKJmJl+IFL1h0xjoojo7VWrzUiTS0YbAXuTVgFTtFrBdaOS23QkXOlEKSacmBhHLpVIw+/rHfyCY9J+9JOHvvk57vZ2ZP1nred6/9MBPy67vW2munqpAk6WgeM+kGJEkrn2EhSeoyLCRJXYaFJKnLsJAkda2ddAOjsG7dupqenp50G5J0Qrnzzjs/W1VTC409KsNienqa2dnZSbchSSeUJJ9abMzTUJKkLsNCktRlWEiSukYWFkl2Jtmf5O4Fxn4lSSVZ1/aT5PVJ5pJ8OMmzhuZuTfKJ9to6qn4lSYsb5criGuCcI4tJNgLPBz49VD4X2Nxe24Gr2txTgcuA5wBnAJclOWWEPUuSFjCysKiq24ADCwxdAbwaGH6C4RZgVw3cDpyc5KnAC4BbqupAVR0EbmGBAJIkjdZYr1kk2QLsq6oPHTG0HtgztL+31RarL3Ts7Ulmk8zOz88vY9eSpLGFRZInAL8B/NYojl9VO6pqpqpmpqYW/E6JJOk4jXNl8Z3AJuBDSe4DNgB3JfkWYB+wcWjuhlZbrC5JGqOxfYO7qj4CfPPh/RYYM1X12SS7gVcmuZ7BxewHq+r+JO8Gfm/oovbzgdeMo99n/9qucXyMTjB3/uHLJt2CNBGjvHX2OuB9wNOS7E2y7SjTbwbuBeaAvwJ+DqCqDgC/A7y/vV7bapKkMRrZyqKqLuqMTw9tF3DJIvN2AjuXtTlJ0jHxG9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6hpZWCTZmWR/kruHan+Y5D+SfDjJ25OcPDT2miRzST6e5AVD9XNabS7JpaPqV5K0uFGuLK4Bzjmidgvw9Kr6PuA/gdcAJDkduBD4nvaev0iyJska4M+Bc4HTgYvaXEnSGI0sLKrqNuDAEbV/qKpDbfd2YEPb3gJcX1X/VVWfBOaAM9prrqruraqvANe3uZKkMZrkNYtXAH/XttcDe4bG9rbaYvVHSLI9yWyS2fn5+RG0K0mr10TCIslvAoeANy/XMatqR1XNVNXM1NTUch1WkgSsHfcHJnk58GPA2VVVrbwP2Dg0bUOrcZS6JGlMxrqySHIO8GrgRVX10NDQbuDCJI9LsgnYDPw78H5gc5JNSU5icBF89zh7liSNcGWR5DrgLGBdkr3AZQzufnoccEsSgNur6meq6qNJbgQ+xuD01CVV9T/tOK8E3g2sAXZW1UdH1bMkaWEjC4uqumiB8tVHmf864HUL1G8Gbl7G1iRJx8hvcEuSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpa2RhkWRnkv1J7h6qnZrkliSfaH+e0upJ8vokc0k+nORZQ+/Z2uZ/IsnWUfUrSVrcKFcW1wDnHFG7FLi1qjYDt7Z9gHOBze21HbgKBuECXAY8BzgDuOxwwEiSxmdkYVFVtwEHjihvAa5t29cC5w/Vd9XA7cDJSZ4KvAC4paoOVNVB4BYeGUCSpBEb9zWL06rq/rb9AHBa214P7Bmat7fVFqs/QpLtSWaTzM7Pzy9v15K0yk3sAndVFVDLeLwdVTVTVTNTU1PLdVhJEuMPi8+000u0P/e3+j5g49C8Da22WF2SNEbjDovdwOE7mrYCNw3VX9buijoTeLCdrno38Pwkp7QL289vNUnSGK0d1YGTXAecBaxLspfBXU2/D9yYZBvwKeCCNv1m4DxgDngIuBigqg4k+R3g/W3ea6vqyIvmkqQRG1lYVNVFiwydvcDcAi5Z5Dg7gZ3L2Jok6Rj5DW5JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdU0kLJK8KslHk9yd5Lokj0+yKckdSeaS3JDkpDb3cW1/ro1PT6JnSVrNxh4WSdYDvwDMVNXTgTXAhcAfAFdU1XcBB4Ft7S3bgIOtfkWbJ0kao0mdhloLfEOStcATgPuB5wFvaePXAue37S1tnzZ+dpKMsVdJWvWWFBZJbl1KbSmqah9wOfBpBiHxIHAn8PmqOtSm7QXWt+31wJ723kNt/lMW6Gd7ktkks/Pz88fTmiRpEUcNi3Yt4VRgXZJTkpzaXtN89R/zY5LkFAarhU3AtwLfCJxzPMcaVlU7qmqmqmampqa+3sNJkoas7Yz/NPBLDP5RvxM4fPrnC8CfHedn/jDwyaqaB0jyNuC5wMlJ1rbVwwZgX5u/D9gI7G2nrZ4MfO44P1uSdByOurKoqiurahPwq1X1HVW1qb2eUVXHGxafBs5M8oR27eFs4GPAPwIvbnO2Aje17d1tnzb+nqqq4/xsSdJx6K0sAKiqP03yA8D08HuqatexfmBV3ZHkLcBdwCHgA8AO4G+B65P8bqtd3d5yNfCmJHPAAQZ3TkmSxmhJYZHkTcB3Ah8E/qeVCzjmsACoqsuAy44o3wucscDch4GXHM/nSJKWx5LCApgBTvf0jyStTkv9nsXdwLeMshFJ0sq11JXFOuBjSf4d+K/Dxap60Ui6kiStKEsNi98eZROSpJVtqXdD/dOoG5EkrVxLvRvqiwzufgI4CXgs8OWqetKoGpMkrRxLXVk88fB2+yLdFuDMUTUlSVpZjvmpszXwDuAFI+hHkrQCLfU01E8M7T6GwfcuHh5JR5KkFWepd0O9cGj7EHAfg1NRkqRVYKnXLC4edSOSpJVrqT9+tCHJ25Psb6+3Jtkw6uYkSSvDUi9wv5HBo8K/tb3e2WqSpFVgqWExVVVvrKpD7XUN4M/RSdIqsdSw+FySn0qypr1+Cn+tTpJWjaWGxSuAC4AHgPsZ/GLdy0fUkyRphVnqrbOvBbZW1UGAJKcClzMIEUnSo9xSVxbfdzgoAKrqAPDM0bQkSVpplhoWj0lyyuGdtrJY6qpEknSCW+o/+H8EvC/J37T9lwCvG01LkqSVZqnf4N6VZBZ4Xiv9RFV9bHRtSZJWkiWfSmrhsCwBkeRk4A3A0xn8TsYrgI8DNwDTDJ49dUFVHWyPRL8SOA94CHh5Vd21HH1IkpbmmB9RvkyuBP6+qr4beAZwD3ApcGtVbQZubfsA5wKb22s7cNX425Wk1W3sYZHkycAPAVcDVNVXqurzDJ5ie22bdi1wftveAuxqv6NxO3BykqeOuW1JWtUmsbLYBMwDb0zygSRvSPKNwGlVdX+b8wBwWtteD+wZev/eVvsaSbYnmU0yOz8/P8L2JWn1mURYrAWeBVxVVc8EvsxXTzkBg1/j46u/+b0kVbWjqmaqamZqysdWSdJymkRY7AX2VtUdbf8tDMLjM4dPL7U/97fxfcDGofdvaDVJ0piMPSyq6gFgT5KntdLZDO6y2g1sbbWtwE1tezfwsgycCTw4dLpKkjQGk/oW9s8Db05yEnAvcDGD4LoxyTbgUwweXAhwM4PbZucY3Drrr/ZJ0phNJCyq6oPAzAJDZy8wt4BLRt6UJGlRk/qehSTpBGJYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXRMLiyRrknwgybva/qYkdySZS3JDkpNa/XFtf66NT0+qZ0larSa5svhF4J6h/T8Arqiq7wIOAttafRtwsNWvaPMkSWM0kbBIsgH4UeANbT/A84C3tCnXAue37S1tnzZ+dpsvSRqTSa0s/gR4NfC/bf8pwOer6lDb3wusb9vrgT0AbfzBNv9rJNmeZDbJ7Pz8/Ch7l6RVZ+xhkeTHgP1VdedyHreqdlTVTFXNTE1NLeehJWnVWzuBz3wu8KIk5wGPB54EXAmcnGRtWz1sAPa1+fuAjcDeJGuBJwOfG3/bkrR6jX1lUVWvqaoNVTUNXAi8p6p+EvhH4MVt2lbgpra9u+3Txt9TVTXGliVp1VtJ37P4deCXk8wxuCZxdatfDTyl1X8ZuHRC/UnSqjWJ01D/r6reC7y3bd8LnLHAnIeBl4y1MUnS11hJKwtJ0gplWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV1rx/2BSTYCu4DTgAJ2VNWVSU4FbgCmgfuAC6rqYJIAVwLnAQ8BL6+qu8bdt7SSfPq13zvpFrQCfdtvfWRkx57EyuIQ8CtVdTpwJnBJktOBS4Fbq2ozcGvbBzgX2Nxe24Grxt+yJK1uYw+Lqrr/8Mqgqr4I3AOsB7YA17Zp1wLnt+0twK4auB04OclTx9y2JK1qE71mkWQaeCZwB3BaVd3fhh5gcJoKBkGyZ+hte1vtyGNtTzKbZHZ+fn5kPUvSajSxsEjyTcBbgV+qqi8Mj1VVMbiesWRVtaOqZqpqZmpqahk7lSRNJCySPJZBULy5qt7Wyp85fHqp/bm/1fcBG4fevqHVJEljMvawaHc3XQ3cU1V/PDS0G9jatrcCNw3VX5aBM4EHh05XSZLGYOy3zgLPBV4KfCTJB1vtN4DfB25Msg34FHBBG7uZwW2zcwxunb14vO1KksYeFlX1L0AWGT57gfkFXDLSpiRJR+U3uCVJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUdcKERZJzknw8yVySSyfdjyStJidEWCRZA/w5cC5wOnBRktMn25UkrR4nRFgAZwBzVXVvVX0FuB7YMuGeJGnVWDvpBpZoPbBnaH8v8JzhCUm2A9vb7peSfHxMva0G64DPTrqJlSCXb510C3ok/34edlm+3iN8+2IDJ0pYdFXVDmDHpPt4NEoyW1Uzk+5DWoh/P8fjRDkNtQ/YOLS/odUkSWNwooTF+4HNSTYlOQm4ENg94Z4kadU4IU5DVdWhJK8E3g2sAXZW1Ucn3NZq4uk9rWT+/RyDVNWke5AkrXAnymkoSdIEGRaSpC7DQkflY1a0EiXZmWR/krsn3ctqYVhoUT5mRSvYNcA5k25iNTEsdDQ+ZkUrUlXdBhyYdB+riWGho1noMSvrJ9SLpAkyLCRJXYaFjsbHrEgCDAsdnY9ZkQQYFjqKqjoEHH7Myj3AjT5mRStBkuuA9wFPS7I3ybZJ9/Ro5+M+JEldriwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEgTkGT68BNTk8wkeX3bPivJD0y2O+mRToifVZUezapqFphtu2cBXwL+bWINSQtwZSEdoyS/meQ/k/xLkuuS/GqS9yaZaePrktzXtqeT/HOSu9rrEauGtpp4V5Jp4GeAVyX5YJIfTPLJJI9t8540vC+NkysL6RgkeTaDx558P4P//9wF3HmUt+wHfqSqHk6yGbgOmFloYlXdl+QvgS9V1eXt894L/Cjwjva5b6uq/16m/znSkrmykI7NDwJvr6qHquoL9J+V9Vjgr5J8BPgbBj8idSzeAFzcti8G3niM75eWhSsLaXkc4qv/8fX4ofqrgM8Az2jjDx/LQavqX9uprLOANVXlz4hqIlxZSMfmNuD8JN+Q5InAC1v9PuDZbfvFQ/OfDNxfVf8LvBRY0zn+F4EnHlHbBfw1rio0QYaFdAyq6i7gBuBDwN8xeIw7wOXAzyb5ALBu6C1/AWxN8iHgu4Evdz7incCPH77A3WpvBk5hcL1DmgifOit9HZL8NkMXpEf0GS8GtlTVS0f1GVKP1yykFSzJnwLnAudNuhetbq4sJEldXrOQJHUZFpKkLsNCktRlWEiSugwLSVLX/wEqE7zfAUL7nQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VikrYsyiyFMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}